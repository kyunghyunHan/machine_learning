# machine_learning

## 개념

- 인공지능 > 머신러넝 >딥러닝
- 인공지능 : 인간의 지능을 모방 문제해결을 위해 사람처럼 학습
- 인간의 학습능력을 기계를 통해 구현하는 분야
- 심층 신경망 기반의 머신러닝 방법

## 처리과정

- 학습단계 - 추론단계

## 기본요소

- n차원의 열벡터로 표현
- 특징추출 → 데이터에서 불필요한 정보를 제거하고 처리를 위한 핵심적 정보를 얻는 것
- 목적함수 → 주어진 데이터 집합을 이용하여 학습 시스템이 달성해야 하는 목표를 기계가 알 수 있는 수학적 함수로 정의한 것
- 오차함수 → 학습 시스템의 출력과 원하는 출력의 차이(“오차”)로 정의되는 목적함수
- 성능 평가 기준 → 학습오차, 테스트 오차, 일반화 오차
- 교차검증법 → 제한된 데이터 집합을 이용하여 일반화 오차에 좀 더 근접한 오차값을 얻어 내는 방법

## 주제

- 주제:분류,회귀,군집화,특징추출
- 분류:입력데이터가 어떤 부류에 속하는지 자동으로 판단하는 문제
- 회귀:학습을 통해 입력변수와 원하는 출력변수 사이의 매핑 관계를 찾는것
- 군집화:주어지는 클래스 정보 없이 단순히 하나의 덩어리로 이루어진 데이터를 받아서 데이터의 데이터의 성질 또는 분포 특성 등을 바탕으로 유사한 데이터끼리 묶어서 임의로 복수 개의 클러스터로 만드는것

## 학습

- 지도학습
- 비지도학습
- 강화학습
- 과다적합

## 선형회귀

- 역학에서 금융 및 천문학에 널리사용
- GLM참조

## 분류

- 분류 → 주어진 데이터 집합에 대해 이미 정의된 몇 개의 클래스(부류)로 입력을 구분하는 문제 → 목표 출력값을 사용하여 학습을 진행하는 지도학습을 적용
- 분류기의 종류 → 베이즈 분류기, K–최근접이웃 분류기, 로지스틱 회귀, 결정 트리, SVM, 신경망 등

## 베이즈 분류기

- 주어진 데이터가 각 클래스로부터 생성되었을 후험확률(사후확률)를 계산하고, 그 값이 가장 큰 클래스로 분류를 수행 → 후험확률은 학습 데이터를 이용하여 추정된 클래스별 분포함수를 이용하여 계산됨
- 우도비 분류 → 각 클래스에서 데이터가 관찰된 확률밀도의 비율(“우도비”)에 의한 분류
- 베이즈 분류기 → 후험확률에 대한 베이즈 정리로부터 유도된 판별함수를 이용하여 분류하는 방식
- 이진 분류 문제의 경우 두 확률밀도함수의 곡선이 만나는 지점이 오류의 확률이 최소인 결정경계가 되며, 전체 데이터 집합에서 각 클래스가 차지하는 비율에 따라서 결정경계가 조정됨
- 클래스별 확률밀도함수가 가우시안 분포를 따르는 경우 공분산행렬의 형태에 따라 결정경계와 판별함수가 달라짐 → 최소거리 분류기, 마할라노비스 거리, 정규화된 유클리디안 거리

## K–최근접이웃 분류기

최근접이웃 분류기 → 클래스와 상관없이 모든 데이터 중 가장 작은 거리값을 가지는 데이터를 찾아 그 데이터가 속하는 클래스로 할당하는 방법 → “K=1인 K-최근접이웃 분류기”

- K–최근접이웃 분류기(K–NN) → 주어진 데이터로부터 거리가 가까운 순서대로 K개의 데이터를 찾은 후, 그중 가장 많은 수의 데이터가 속한 클래스로 할당하는 방법 → 분류 수행을 위해 항상 학습 데이터를 저장해야 함 → 비용(계산량, 메모리) 문제 발생
- K–NN 분류기 → 매우 비선형적인 결정경계를 가지며, 복잡한 데이터 분포에 대해서 비교적 잘 작동 → 분류를 위해서는 학습 데이터를 항상 저장해야 하는 문제점을 가짐.
- 가우시안 베이즈 분류기 → 각 클래스에 대해 가우시안 분포를 미리 가정하고 파라미터를 추정하므로, 잘못된 가정에 따른 성능 저하의 위험성이 존재 → 학습 데이터로부터 각 클래스의 평균과 공분산을 계산한 후에는 학습 데이터가 더 이상 필요하지 않음.
- K–NN 분류기의 설계 고려사항 → 적절한 K값과 거리 함수의 선택
- 자주 쓰이는 거리 함수의 종류 → 2차 노름(유클리디안 거리), 1차 노름, p차 노름, 내적, 코사인 거리, 정규화된 유클리디안 거리, 마할라노비스 거리 등
